{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T10:35:49.526646Z",
     "start_time": "2024-05-02T10:35:37.357074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Run import RunBuilder as RB\n",
    "from Run import RunManager as RM\n",
    "from DataLoading import UdacityDataset as UD\n",
    "from DataLoading import ConsecutiveBatchSampler as CB\n",
    "\n",
    "from model import TransferLearning as TLearn\n",
    "\n",
    "%run Visualization/Visualization.ipynb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_json(data_dir):\n",
    "    json_file_name = \"dataset.json\"\n",
    "    json_file_path = os.path.join(data_dir, json_file_name)\n",
    "    print(json_file_path)\n",
    "    if os.path.exists(json_file_path):\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    else:\n",
    "        print(f\"The JSON file '{json_file_name}' does not exist in the directory '{data_dir}'.\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T10:35:49.531437Z",
     "start_time": "2024-05-02T10:35:49.527653Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training / Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T10:57:37.047587Z",
     "start_time": "2024-05-02T10:56:35.282319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run: Run(file='3DCNN_Paper', learning_rate=0.001, batch_size=5, seq_len=5, num_workers=0)\n",
      "D:\\PythonProjects\\Self-Driving-Car\\data\\dataset.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:   0%|          | 0/5 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 115\u001B[0m\n\u001B[0;32m    111\u001B[0m     m\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 115\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 99\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     95\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(network\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mrun\u001B[38;5;241m.\u001B[39mlearning_rate, betas\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.9\u001B[39m, \u001B[38;5;241m0.999\u001B[39m), eps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-08\u001B[39m,\n\u001B[0;32m     96\u001B[0m                        weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[0;32m     98\u001B[0m training_loader, validation_loader \u001B[38;5;241m=\u001B[39m setup_data_loaders(data_dir, run)\n\u001B[1;32m---> 99\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m    102\u001B[0m     m\u001B[38;5;241m.\u001B[39mbegin_epoch()\n",
      "File \u001B[1;32mD:\\PythonProjects\\Self-Driving-Car\\Run\\RunManager.py:37\u001B[0m, in \u001B[0;36mRunManager.begin_run\u001B[1;34m(self, run, network, loader)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtb \u001B[38;5;241m=\u001B[39m SummaryWriter(comment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Add graph to tensorboard\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m images, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m grid \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mmake_grid(images[:\u001B[38;5;241m10\u001B[39m])  \u001B[38;5;66;03m# Display first 10 images\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtb\u001B[38;5;241m.\u001B[39madd_image(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m'\u001B[39m, grid)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\PythonProjects\\Self-Driving-Car\\DataLoading\\UdacityDataset.py:78\u001B[0m, in \u001B[0;36mUdacityDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_tensor(idx):\n\u001B[0;32m     76\u001B[0m     idx \u001B[38;5;241m=\u001B[39m idx\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m---> 78\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PythonProjects\\Self-Driving-Car\\DataLoading\\UdacityDataset.py:60\u001B[0m, in \u001B[0;36mUdacityDataset.read_data\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     58\u001B[0m batch_data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(idx, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading data\u001B[39m\u001B[38;5;124m\"\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m---> 60\u001B[0m     batch_data\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_data_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     61\u001B[0m images \u001B[38;5;241m=\u001B[39m {cam: torch\u001B[38;5;241m.\u001B[39mstack([data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m'\u001B[39m][cam] \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m batch_data]) \u001B[38;5;28;01mfor\u001B[39;00m cam \u001B[38;5;129;01min\u001B[39;00m\n\u001B[0;32m     62\u001B[0m           [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcenter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n\u001B[0;32m     63\u001B[0m batch \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m'\u001B[39m: images,\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m: [data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m batch_data],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspeed\u001B[39m\u001B[38;5;124m'\u001B[39m: torch\u001B[38;5;241m.\u001B[39mstack([data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspeed\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m batch_data])\n\u001B[0;32m     69\u001B[0m }\n",
      "File \u001B[1;32mD:\\PythonProjects\\Self-Driving-Car\\DataLoading\\UdacityDataset.py:33\u001B[0m, in \u001B[0;36mUdacityDataset.read_data_single\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_data_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     32\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Reads data for a single index.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m     frame_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m())[idx]\n\u001B[0;32m     34\u001B[0m     entry \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[frame_key]\n\u001B[0;32m     36\u001B[0m     images \u001B[38;5;241m=\u001B[39m {cam: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecode_image(entry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m'\u001B[39m][cam]) \u001B[38;5;28;01mfor\u001B[39;00m cam \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcenter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def initialize_parameters():\n",
    "    return OrderedDict(\n",
    "        file=['3DCNN_Paper'],\n",
    "        learning_rate=[0.001],\n",
    "        batch_size=[5],\n",
    "        seq_len=[5],\n",
    "        num_workers=[0],\n",
    "    )\n",
    "\n",
    "\n",
    "def setup_data_loaders(data_dir, run):\n",
    "    json_dataset = read_json(data_dir)\n",
    "    dataset_loader = UD.UdacityDataset(dataset=json_dataset)\n",
    "    training_set, validation_set = dataset_loader.split_dataset()\n",
    "\n",
    "    training_cbs = CB.ConsecutiveBatchSampler(\n",
    "        data_source=training_set, batch_size=run.batch_size, shuffle=True, drop_last=False, seq_len=run.seq_len\n",
    "    )\n",
    "    validation_cbs = CB.ConsecutiveBatchSampler(\n",
    "        data_source=validation_set, batch_size=run.batch_size, shuffle=False, drop_last=False, seq_len=run.seq_len\n",
    "    )\n",
    "\n",
    "    training_loader = DataLoader(\n",
    "        training_set, sampler=training_cbs, num_workers=run.num_workers, collate_fn=identity_collate\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        validation_set, sampler=validation_cbs, num_workers=run.num_workers, collate_fn=identity_collate\n",
    "    )\n",
    "\n",
    "    return training_loader, validation_loader\n",
    "\n",
    "\n",
    "def identity_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch, training_loader, network, optimizer, device):\n",
    "    print(f\"Epoch {epoch + 1}/10 - Training\")\n",
    "    for training_sample in tqdm(training_loader, total=int(len(training_loader.dataset) / training_loader.batch_size)):\n",
    "        training_sample['image'] = torch.Tensor(\n",
    "            resize(training_sample['image'], (training_loader.batch_size, training_loader.seq_len, 3, 120, 320),\n",
    "                   anti_aliasing=True))\n",
    "        training_sample['image'] = training_sample['image'].permute(0, 2, 1, 3, 4)\n",
    "\n",
    "        # Get data and train model\n",
    "        images, angles = training_sample['images'], training_sample['angles']\n",
    "        images, angles = images.to(device), angles.to(device)\n",
    "\n",
    "        predictions = network(images).squeeze().permute(1, 0).to(device)\n",
    "\n",
    "        # Compute loss and update weights\n",
    "        loss = F.mse_loss(predictions, angles)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def validate_model(validation_loader, network, device):\n",
    "    network.eval()\n",
    "    total_validation_loss = 0\n",
    "    num_samples = 0\n",
    "    for validation_sample in tqdm(validation_loader,\n",
    "                                  total=int(len(validation_loader.dataset) / validation_loader.batch_size)):\n",
    "        validation_sample['image'] = torch.Tensor(\n",
    "            resize(validation_sample['image'], (validation_loader.batch_size, validation_loader.seq_len, 3, 120, 320),\n",
    "                   anti_aliasing=True))\n",
    "        validation_sample['image'] = validation_sample['image'].permute(0, 2, 1, 3, 4)\n",
    "\n",
    "        images, angles = validation_sample['images'], validation_sample['angles']\n",
    "        images, angles = images.to(device), angles.to(device)\n",
    "\n",
    "        predictions = network(images).squeeze().permute(1, 0).to(device)\n",
    "        if angles.shape[0] != predictions.shape[0]:\n",
    "            predictions = predictions[-angles.shape[0]:]\n",
    "\n",
    "        validation_loss = F.mse_loss(predictions, angles)\n",
    "        total_validation_loss += validation_loss.item() * images.size(0)\n",
    "        num_samples += images.size(0)\n",
    "\n",
    "    return total_validation_loss / num_samples\n",
    "\n",
    "\n",
    "def main():\n",
    "    parameters = initialize_parameters()\n",
    "    m = RM.RunManager()\n",
    "    script_dir = os.getcwd()\n",
    "    data_dir = os.path.join(script_dir, 'data')\n",
    "\n",
    "    for run in RB.RunBuilder.get_runs(parameters):\n",
    "        print(f\"Starting run: {run}\")\n",
    "        network = TLearn.TLearning().to(device)\n",
    "        optimizer = optim.Adam(network.parameters(), lr=run.learning_rate, betas=(0.9, 0.999), eps=1e-08,\n",
    "                               weight_decay=0.001)\n",
    "\n",
    "        training_loader, validation_loader = setup_data_loaders(data_dir, run)\n",
    "        m.begin_run(run, network, training_loader)\n",
    "\n",
    "        for epoch in range(10):\n",
    "            m.begin_epoch()\n",
    "            train_one_epoch(epoch, training_loader, network, optimizer, device)\n",
    "            validation_loss = validate_model(validation_loader, network, device)\n",
    "            m.track_loss(validation_loss, 'validation')\n",
    "            print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "            m.end_epoch()\n",
    "            torch.save(network.state_dict(), f\"saved_models/CNN3D/epoch-{epoch}.pth\")\n",
    "\n",
    "        m.end_run()\n",
    "    m.save('result')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "011ebb92fbd24a819de2f622a59912ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_607feafdf31142aea308be66f666b504",
       "style": "IPY_MODEL_42ad982373e04ad8be4d990fba88c551",
       "value": " 6/1081 [00:07&lt;20:48,  1.16s/it]"
      }
     },
     "42ad982373e04ad8be4d990fba88c551": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "607feafdf31142aea308be66f666b504": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7b00bc7d78d841de990c6833c7066e8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d569713a50a248f0800bbcfc12eab14f",
        "IPY_MODEL_011ebb92fbd24a819de2f622a59912ad"
       ],
       "layout": "IPY_MODEL_b7d0898a52a9461aa33c3720aec562b4"
      }
     },
     "85e3c0c5fc464ebb9b00d0e7c30eabcb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b7d0898a52a9461aa33c3720aec562b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d569713a50a248f0800bbcfc12eab14f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "danger",
       "description": "  1%",
       "layout": "IPY_MODEL_85e3c0c5fc464ebb9b00d0e7c30eabcb",
       "max": 1081,
       "style": "IPY_MODEL_f1d240b7ad4f475d950d95b033d66e85",
       "value": 6
      }
     },
     "f1d240b7ad4f475d950d95b033d66e85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
